---
title: "Effects of Temperature and Precipitation on Bike Ridership"
format: 
  html: 
    toc: false
    page-layout: full
author: Christopher Tan
execute: 
  freeze: auto
---

## 1. Overview

Citi Bike demand can change substantially from one day to the next, and weather is one of the most direct reasons why. Unlike long recreational rides, many Citi Bike trips in Manhattan are short, purpose driven trips such as commutes to work, quick errands, or first and last mile connections to the subway. Because these trips are often discretionary at the margin, riders continuously weigh the convenience of biking against comfort and perceived safety.

Temperature plays a key role in this decision making process. Warmer days generally lower the physical and mental barrier to riding, making biking feel easier and more pleasant, which can lead to higher overall trip volume. In contrast, colder days can discourage riding due to discomfort. Precipitation adds another layer of friction by reducing comfort and increasing safety concerns such as slippery roads and reduced visibility, leading some riders to choose alternative modes of transportation.

Together, these patterns suggest that daily weather conditions may systematically influence Citi Bike usage. To quantify this relationship and move beyond intuition, this analysis focuses on the following question:

> *How do daily temperature and precipitation levels affect Citi Bike trip volume in Manhattan?*

## 2. Data Preparation

### Install packages

First, we must load the following:

-   `data.table` for fast CSV reading and big-data manipulation

-   `sf` for spatial operations (point-in-polygon)

-   `utils` for downloads

-   `httr` + `jsonlite` for calling the weather API and parsing JSON

-   `htmltools` for the iFrame embed

-   `gt` for creating clean tables in Quarto

-   `ranger` for fitting fast random forest models

```{r}
library(data.table)
library(sf)
library(utils)
library(httr)
library(jsonlite)
library(htmltools)
library(gt)
library(ranger)
```

### Directories

```{r}
raw_dir <- "data/raw"          # zipped tripdata
out_dir <- "data/processed"    # cleaned outputs
gis_dir <- "data/gis"          # borough shapefile

dir.create(raw_dir, showWarnings = FALSE, recursive = TRUE)
dir.create(out_dir, showWarnings = FALSE, recursive = TRUE)
dir.create(gis_dir, showWarnings = FALSE, recursive = TRUE)

```

### Download Settings

Two stability tweaks for large downloads:

-   longer timeout

-   `libcurl` download method

```{r}
options(download.file.method = "libcurl")

```

### Time Window

Define the month labels Citi Bike uses (`YYYYMM`) and the base URL.

```{r}
months <- format(
  seq(as.Date("2024-10-01"), as.Date("2025-10-01"), by = "month"),
  "%Y%m"
)
base_url <- "https://s3.amazonaws.com/tripdata"
```

### Download Manhattan Polygon (GIS)

We must download NYC borough boundaries, read them as an `sf` object, convert to standard lat/lon (EPSG:4326), then extract **only Manhattan** as `manhattan_poly`. That polygon is used later to filter trips.

```{r}
borough_url <- "https://www.nyc.gov/assets/planning/download/zip/data-maps/open-data/nybb_16a.zip"
borough_zip <- file.path(gis_dir, "nyc_boroughs.zip")

if (!file.exists(borough_zip)) {
  message("Downloading NYC borough boundaries shapefile...")
  download.file(borough_url, borough_zip, mode = "wb")
}

unzip(borough_zip, exdir = gis_dir)

shp_file <- list.files(gis_dir, pattern = "\\.shp$", recursive = TRUE, full.names = TRUE)[1]
if (is.na(shp_file)) stop("No .shp file found in ", gis_dir, " after unzip.")

boroughs <- st_read(shp_file, quiet = TRUE)
boroughs <- st_transform(boroughs, 4326)

if (!("BoroName" %in% names(boroughs))) {
  stop("Could not find a 'BoroName' column in borough shapefile.")
}

manhattan_poly <- boroughs[boroughs$BoroName == "Manhattan", ]
if (nrow(manhattan_poly) == 0) stop("Manhattan polygon not found in boroughs shapefile.")

```

### Download from Open-Meteo

Set location:

```{r}
# used Midtown as our reference point
latitude  <- 40.75493
longitude <- -73.98402
```

Query Open-Meteo for daily:

-   mean temperature (`temperature_2m_mean`)

-   precipitation sum (`precipitation_sum`)

```{r}
get_monthly_weather <- function(lat, lon, start_date, end_date, max_attempts = 5) {
  
  # Use archive endpoint for past dates (more appropriate for historical pulls)
  base_url <- "https://api.open-meteo.com/v1/forecast"
  if (as.Date(start_date) < Sys.Date()) {
    base_url <- "https://archive-api.open-meteo.com/v1/archive"
  }
  
  params <- list(
    latitude           = lat,
    longitude          = lon,
    start_date         = start_date,
    end_date           = end_date,
    daily              = "temperature_2m_mean,precipitation_sum",
    temperature_unit   = "fahrenheit",
    precipitation_unit = "inch",
    timezone           = "America/New_York"
  )
  
  for (attempt in seq_len(max_attempts)) {
    
    # Robust request: longer timeout + safe error handling
    resp <- tryCatch(
      GET(base_url, query = params, timeout(60)),
      error = function(e) e
    )
    
    # If the request failed (DNS/timeout/etc.), retry with backoff
    if (inherits(resp, "error")) {
      message("Weather request error (attempt ", attempt, "): ", resp$message)
      Sys.sleep(2 ^ attempt)
      next
    }
    
    # If server returns non-200, retry (could be temporary)
    if (status_code(resp) != 200) {
      message("Weather request failed (attempt ", attempt, ") status: ",
              status_code(resp))
      Sys.sleep(2 ^ attempt)
      next
    }
    
    # Parse JSON
    dat <- fromJSON(content(resp, "text", encoding = "UTF-8"))
    
    # If daily data is missing, retry
    if (is.null(dat$daily$time)) {
      message("No daily data returned (attempt ", attempt, ") for ",
              start_date, "–", end_date)
      Sys.sleep(2 ^ attempt)
      next
    }
    
    # Success: return clean daily table
    return(data.table::data.table(
      date        = as.Date(dat$daily$time),
      temp_mean_F = dat$daily$temperature_2m_mean,
      precip_in   = dat$daily$precipitation_sum
    ))
  }
  
  warning("Failed to fetch weather after ", max_attempts, " attempts for ",
          start_date, "–", end_date)
  NULL
}

```

Build a list of month ranges, call the API month-by-month, combine results, and save.

-   `Sys.sleep(0.5)` is a rate-limit to reduce API stress

-   `head()`/`tail()` prints are quick checks to make sure that data has properly settled

```{r}
date_ranges <- list(
  list(start = "2024-10-01", end = "2024-10-31"),
  list(start = "2024-11-01", end = "2024-11-30"),
  list(start = "2024-12-01", end = "2024-12-31"),
  list(start = "2025-01-01", end = "2025-01-31"),
  list(start = "2025-02-01", end = "2025-02-28"),
  list(start = "2025-03-01", end = "2025-03-31"),
  list(start = "2025-04-01", end = "2025-04-30"),
  list(start = "2025-05-01", end = "2025-05-31"),
  list(start = "2025-06-01", end = "2025-06-30"),
  list(start = "2025-07-01", end = "2025-07-31"),
  list(start = "2025-08-01", end = "2025-08-31"),
  list(start = "2025-09-01", end = "2025-09-30"),
  list(start = "2025-10-01", end = "2025-10-31")
)

cat("Getting daily weather data for Manhattan\n")
weather_list <- vector("list", length(date_ranges))

for (i in seq_along(date_ranges)) {
  dr <- date_ranges[[i]]
  cat("  ", dr$start, "–", dr$end, "...\n")
  weather_list[[i]] <- get_monthly_weather(latitude, longitude, dr$start, dr$end)
  Sys.sleep(0.5)
}

weather_daily <- rbindlist(weather_list, use.names = TRUE, fill = TRUE)

print(head(weather_daily))
print(tail(weather_daily))

weather_out <- file.path(out_dir, "weather_daily_10036_202410_202510.rds")
saveRDS(weather_daily, weather_out)
message("Saved daily weather to: ", weather_out)
```

## 3. Data Filtering

### Download, Unzip, Read, Filter for Manhattan Only Trips

First, we must download all files relevant to October 2024 to October 2025 from the Citi Bike website.

Afterwards, we must filter for Manhattan only trips. For one month `m`, return a `data.table` containing only trips whose **starting latitude/longitude** falls inside Manhattan.

::: {.callout-note title="Why start location only?"}
We filter trips by **starting latitude/longitude** because that’s where riders actually makes the decision to rent a bike, so it best reflects *Manhattan demand*.

**Limitations:** This will still include trips that end outside Manhattan, while excluding trips that *start outside* Manhattan but end inside. It also assumes the recorded start coordinates are accurate.
:::

```{r, message=FALSE, warning=FALSE}
download_zip <- function(m, max_attempts = 5) {
  zip_name <- sprintf("%s-citibike-tripdata.zip", m)
  zip_path <- file.path(raw_dir, zip_name)
  zip_url  <- paste0(base_url, "/", zip_name)

  if (file.exists(zip_path)) {
    message("Zip already exists: ", zip_name)
    return(zip_path)
  }

  for (attempt in seq_len(max_attempts)) {
    message("Downloading (attempt ", attempt, "): ", zip_name)

    if (file.exists(zip_path)) file.remove(zip_path)

    ok <- tryCatch({
      utils::download.file(zip_url, zip_path, mode = "wb", quiet = FALSE)
      TRUE
    }, error = function(e) {
      message("  Download error: ", conditionMessage(e))
      FALSE
    })

    if (ok && file.exists(zip_path)) {
      message("  Download complete: ", zip_name)
      return(zip_path)
    }

    Sys.sleep(10 * attempt)
  }

  stop("Failed to download after ", max_attempts, " attempts: ", zip_url)
}

process_month_manhattan <- function(m) {
  zip_name <- sprintf("%s-citibike-tripdata.zip", m)
  zip_path <- file.path(raw_dir, zip_name)
  
  # Download if missing
  if (!file.exists(zip_path)) {
    zip_path <- download_zip(m)
  }
  
  message("\n Processing month: ", m)
  
  # 1) Unzip to a temporary directory
  tmpdir <- file.path(tempdir(), m)
  dir.create(tmpdir, showWarnings = FALSE)
  unzip(zip_path, exdir = tmpdir)
  
  # 2) List CSV files inside the unzipped folder
  csv_files <- list.files(tmpdir, pattern = "\\.csv$", full.names = TRUE)
  
  if (length(csv_files) == 0) {
    warning("No CSV files found in ", zip_path)
    unlink(tmpdir, recursive = TRUE)
    return(NULL)
  }
  
  month_list <- vector("list", length(csv_files))
  
  # 3) Process each CSV
  for (i in seq_along(csv_files)) {
    csv <- csv_files[i]
    message("  Reading: ", basename(csv))
    
    dt <- fread(
      csv,
      select = c(
        "started_at",
        "ended_at",
        "start_lat", "start_lng"
      )
    )
    
    # Convert to POSIXct
    dt[, started_at := as.POSIXct(started_at, tz = "America/New_York")]
    dt[, ended_at   := as.POSIXct(ended_at,   tz = "America/New_York")]
    
    # Date/hour format
    dt[, date := as.Date(started_at)]
    dt[, hour := as.integer(format(started_at, "%H"))]
    
    # GIS filter: keep only trips whose starting long. and lat. point are in Manhattan 
    # 1) Drop rows with missing start coordinates
    n_before <- nrow(dt)
    dt <- dt[!is.na(start_lat) & !is.na(start_lng)]
    n_after  <- nrow(dt)
    
    if (n_after == 0L) {
      message("    All rows in this CSV had missing start coords; skipping.")
      month_list[[i]] <- NULL
      next
    }
    
    if (n_after < n_before) {
      message("    Dropped ", n_before - n_after, " rows with missing start coords.")
    }
    
    # 2) Convert start coordinates to sf points
    dt_sf <- st_as_sf(
      dt,
      coords = c("start_lng", "start_lat"),
      crs = 4326,
      remove = FALSE
    )
    
    # 3) Keep only points inside Manhattan polygon
    inside_manhattan <- st_within(dt_sf, manhattan_poly, sparse = FALSE)[, 1]
    dt_manhattan <- dt_sf[inside_manhattan, ]
    
    # 4) Drop geometry to go back to data.table
    dt_manhattan <- as.data.table(st_drop_geometry(dt_manhattan))
    
    if (nrow(dt_manhattan) == 0) {
      message("    No Manhattan-start trips in this chunk after GIS filter.")
      month_list[[i]] <- NULL
      next
    }
    
    month_list[[i]] <- dt_manhattan
    
    rm(dt, dt_sf, dt_manhattan)
    gc()
  }
  
  # 4) Combine all Manhattan-start trips for this month
  month_all <- rbindlist(month_list, use.names = TRUE, fill = TRUE)
  
  # 5) Clean up temp files
  unlink(tmpdir, recursive = TRUE)
  
  month_all
}

all_months_list <- vector("list", length(months))
for (i in seq_along(months)) {
  all_months_list[[i]] <- process_month_manhattan(months[i])
  gc()
}

citibike_manhattan_all <- rbindlist(all_months_list, use.names = TRUE, fill = TRUE)

citibike_out <- file.path(out_dir, "citibike_manhattan_all_202410_202510.rds")
saveRDS(citibike_manhattan_all, citibike_out)
message("Saved Manhattan-start trips to: ", citibike_out)
```

Before, we join our two datasets, we must first clean our raw data directory as there are many files we no longer have any use for.

```{r}
# Find only .zip files (non-recursive)
zip_files <- list.files(
  raw_dir,
  pattern = "\\.zip$",
  full.names = TRUE
)

if (length(zip_files) > 0) {
  message("Deleting ZIP files in ", raw_dir)
  unlink(zip_files, force = TRUE)
  message("Deleted ", length(zip_files), " ZIP files.")
} else {
  message("No ZIP files found in ", raw_dir)
}

```

## 4. Join Bike and Weather Data

To start, we have to load the cleaned Manhattan Citi Bike trips file and the daily weather file that we created earlier.

```{r}
cat("Loading Citi Bike and weather data\n")

## Load data
citibike_path <- "data/processed/citibike_manhattan_all_202410_202510.rds"
weather_path  <- "data/processed/weather_daily_10036_202410_202510.rds"

if (!file.exists(citibike_path)) stop("Missing Citi Bike file")
if (!file.exists(weather_path)) stop("Missing weather file")

citibike <- readRDS(citibike_path)
daily_weather <- readRDS(weather_path)

setDT(citibike)
setDT(daily_weather)
```

Citi Bike data is trip-level (many rows per day), so we first collapse it into one row per day by counting trips.

```{r}
cat("Building daily Citi Bike trip counts\n")

## Build daily trips
citibike[, date := as.Date(started_at)]
daily_trips <- citibike[, .(n_trips = .N), by = .(date)]
daily_trips <- daily_trips[date >= "2024-10-01" & date <= "2025-10-31"]
setorder(daily_trips, date)
```

Now both datasets are daily, so we merge them on date.\
`all.x = TRUE` keeps all days with Citi Bike trips, even if weather is missing.

```{r}
cat("Merging Citi Bike daily counts with weather\n")

## Merge trips + weather
daily <- merge(
  daily_trips,
  daily_weather,
  by = "date",
  all.x = TRUE
)
```

### EDA: Summary Check

Before making any plots or models, we must first check that the data looks correct. This step confirms that there is one row per day, that the dates cover the expected time period, and that ridership, temperature, and precipitation values fall within reasonable ranges. Doing this helps ensure that later results are based on real patterns in the data and not on data errors.

```{r}
cat("Rows (days):", nrow(daily), "\n")
cat("Date range :", min(daily$date, na.rm = TRUE), "to", max(daily$date, na.rm = TRUE), "\n")

dup_days <- daily[, .N, by = date][N > 1]
if (nrow(dup_days) > 0) {
  print(dup_days)
  stop("EDA check failed: duplicated dates found in daily panel.")
} else {
  cat("EDA check: OK — one row per day.\n")
}

summary(daily[, .(n_trips, temp_mean_F, precip_in)])
```

-   The dataset contains 396 days with exactly one observation per day, confirming that the daily aggregation is correct

<!-- -->

-   Daily ridership varies widely, from about 13,000 to 130,000 trips, showing that demand changes a lot from day to day

<!-- -->

-   Temperature covers a large range (about 10°F to 94°F) and changes smoothly across the year, suggesting it strongly affects ridership

### EDA: Outlier Check

To check whether very high ridership days are caused by data problems or by real rider behavior, we look at the weather on those highest-demand days.

```{r}
# Instead of deleting extremes, we inspect whether low/high ridership days align with extreme weather
low5  <- daily[order(n_trips)][1:5,  .(date, n_trips, temp_mean_F, precip_in)]
high5 <- daily[order(-n_trips)][1:5, .(date, n_trips, temp_mean_F, precip_in)]

cat("Lowest 5 ridership days:\n");  low5
cat("\nHighest 5 ridership days:\n"); high5

# Simple rule-of-thumb flags
daily[, flag_low_trips := n_trips < quantile(n_trips, 0.01, na.rm = TRUE)]
daily[, flag_high_trips := n_trips > quantile(n_trips, 0.99, na.rm = TRUE)]

daily[flag_low_trips == TRUE,  .(n_days = .N,
                                 avg_temp = mean(temp_mean_F, na.rm = TRUE),
                                 avg_prec = mean(precip_in, na.rm = TRUE))] |> print()

daily[flag_high_trips == TRUE, .(n_days = .N,
                                 avg_temp = mean(temp_mean_F, na.rm = TRUE),
                                 avg_prec = mean(precip_in, na.rm = TRUE))] |> print()
```

-   There are 4 extremely high-ridership days in the dataset

<!-- -->

-   These days have an average temperature of about 72°F, which is comfortable for biking

-   Average precipitation is very low (\~0.05 inches), indicating mostly dry conditions

<!-- -->

-   These weather patterns are realistic and favorable, suggesting the high ridership reflects true behavior, not data errors

### EDA: Precipitation Threshold

Before studying how rain affects ridership, we first look at how often each rain level appears in the data given certain thresholds.

```{r}
# precipitation likely acts via thresholds, not smoothly
daily[, rain_cat := fifelse(
  is.na(precip_in), NA_character_,
  fifelse(precip_in == 0, "None",
    fifelse(precip_in <= 0.10, "Light",
      fifelse(precip_in <= 0.30, "Moderate", "Heavy")
    )
  )
)]
daily[, rain_cat := factor(rain_cat, levels = c("None","Light","Moderate","Heavy"))]

# Distribution of days by category
daily[, .N, by = rain_cat][order(rain_cat)]
```

-   "None" accounts for more than half of all days

-   Precipitation's predictive value comes from a small subset of days, not from day-to-day variation

-   Because precipitation only influences ridership on a limited number of days, its overall importance can appear smaller in aggregate models

This saves the final day-level dataset that will be used as input for the graphs/models.

```{r}
dir.create("shiny",     showWarnings = FALSE, recursive = TRUE)

cat("Saving combined daily panel\n")

## Save merged panel
panel_path <- "data/processed/daily_trips_weather_202410_202510.rds"
saveRDS(daily, panel_path)

cat("Saved daily panel to:", panel_path, "\n")


## Save merged panel for shiny deployment
panel_path <- "shiny/daily_trips_weather_202410_202510.rds"
saveRDS(daily, panel_path)

cat("Saved daily panel to:", panel_path, "\n")


```

## 5. Plot Data

Now that we’ve joined the Citi Bike and weather data into one daily dataset, we can move on to the visualization portion.

We will be creating two plots that directly answer our weather question:

**(1)** a scatterplot of daily trips versus temperature with a **GAM smooth** to capture any non-linear relationship, and **(2)** a boxplot comparing daily trip volume across **rain intensity categories** to show how precipitation shifts ridership distributions.

To access these plots, please use the interactive dashboard below:

```{r}
## Interactive Dashboard
htmltools::tags$iframe(
  src = "https://citibikenyc.shinyapps.io/appTemp/",
  style = "width:100%; height:900px; border:0;"
)
```

## 6. Results

### What the precipitation figure shows

Starting with the rain boxplot, we see that for days with no rain, the median is around 92,000–95,000 trips. On days with light rain, the median is similar or slightly higher, indicating that very small amounts of rain do not meaningfully deter rider. It's also worth noting that there are also far more days without rain than lightly rainy days. As such, light rain days are more likely to coincide with favorable conditions such as warmer temperatures.

The effect becomes clear once rain reaches moderate levels. When precipitation increases from none to moderate, the median daily trip count falls by roughly 10,000 trips, dropping to about 83,000–85,000 trips.

On days with heavy rain, the median drops to roughly 55,000 trips. That means heavy rain is associated with about 40,000 fewer trips in a single day compared to dry conditions.

### What the temperature figure shows

The temperature plot tells the same story in a different way. On cold days (around 20–30°F), daily ridership usually falls between 30,000 and 50,000 trips. As temperatures rise into the 60s and low 70s, daily trips increase to over 105,000–110,000.

That is a swing of more than 60,000 trips per day across the temperature range. The smooth line also shows that ridership stops increasing once temperatures get very hot (above about 75–80°F), leveling off near 100,000 trips. This suggests that warm weather encourages biking up to a comfortable range, but extreme heat does not continue to increase usage.

### Putting temperature and precipitation together

Taken together, the figures show that temperature and precipitation work in different but complementary ways. Temperature determines how high ridership can go, while precipitation determines how far below that level demand falls. On warm, dry days, ridership regularly exceeds 100,000 trips. On cold or rainy days, daily usage can fall to 50,000 trips or less.

::: callout-note
## Refer to the LOCO table in the group summary report.
:::

To conclude, weather causes very large swings in daily Citi Bike usage. From the figures, we see that changes in temperature and rain can reduce or increase daily ridership by 10,000 trips on moderate days and by more than 60,000 trips when comparing cold or rainy days to warm, dry ones. No other factor in the analysis causes changes anywhere near this large.

Because weather explains such big day-to-day differences, the model relies heavily on it to make accurate predictions. When we remove weather variables from the model, the model loses this key information. As a result, its predictions become much worse: the average prediction error increases by 2,145 trips per day, and the model’s ability to explain variation in ridership drops by 0.186 in R².

This drop in performance is the largest observed when removing any single factor. In simple terms, once the model no longer knows whether a day is warm, cold, dry, or rainy, it struggles to explain why ridership might be around 100,000 trips on one day but closer to 50,000 trips on another. That is why weather emerges as the most important factor in the LOCO analysis.

## 7. Further Analysis: Temperature vs. Precipitation

To assess their relative impact on weather, we will be applying a leave-one-covariate-out (LOCO) approach that compare the predictive contributions of temperature and precipitation. In this analysis, we start with a model that includes both weather variables (temperature and precipitation), then remove one variable at a time and observe how much the model’s performance changes. If removing a variable causes the model’s accuracy to worsen substantially, that variable is considered more important for predicting daily ridership.

We evaluate model performance using two standard metrics:

-   RMSE (Root Mean Squared Error) measures the typical size of the model’s prediction error, expressed in number of trips per day. A lower RMSE means the model’s predictions are closer to the actual observed ridership.

<!-- -->

-    R² (R-squared) measures how much of the day-to-day variation in Citi Bike ridership the model can explain. Higher R² values indicate that the model captures more of the underlying pattern in the data.

### 1. Load Datasets

We load the processed Manhattan Citi Bike trip data and the daily weather data, then convert both into `data.table` objects for efficient data manipulation. All date fields are standardized to ensure the two datasets can be merged accurately at the daily level.

```{r}
trips <- readRDS("data/processed/citibike_manhattan_all_202410_202510.rds")
wx    <- readRDS("data/processed/weather_daily_10036_202410_202510.rds")

setDT(trips)
setDT(wx)

if (!inherits(trips$started_at, "POSIXct")) {
  trips[, started_at := as.POSIXct(started_at, tz = "America/New_York")]
}
trips[, date := as.Date(started_at)]

wx[, date := as.Date(date)]
```

### 2. Define the outcome variable

Because weather conditions vary by day, we aggregate trip-level data into a daily outcome variable, **`n_trips`**, which represents the total number of Citi Bike trips taken on each date. This aligns the outcome with the temporal scale of the weather data.

```{r}
y_daily <- trips[, .(n_trips = .N), by = date]
setorder(y_daily, date)
```

### 3. Select weather predictors

From the weather dataset, we retain only two variables:

-   **`temp_mean_F`**: daily average temperature (°F)

-   **`precip_in`**: total daily precipitation (inches)

Limiting predictors to just these two variables makes sure that the analysis focuses exclusively on comparing the effects of temperature and precipitation, without introducing additional confounding factors.

```{r}
wx_daily <- wx[, .(date, temp_mean_F, precip_in)]
setkey(wx_daily, date)
```

### 4. Create the modeling dataset

We merge the daily trip totals with the daily weather variables by date to form a single modeling dataset. Any days with missing values are removed so that all models are trained and evaluated using the same complete set of observations.

```{r}
dt <- merge(y_daily, wx_daily, by = "date", all.x = TRUE)
dt <- dt[!is.na(n_trips) & !is.na(temp_mean_F) & !is.na(precip_in)]
setorder(dt, date)
```

### 5. Use a train/test split

To prevent information from the future influencing model training, we split the data chronologically. The first 80% of days are used for training, while the remaining 20% are reserved for testing. This time-safe split reflects a realistic forecasting setting.

```{r}
n   <- nrow(dt)
cut <- floor(0.8 * n)
train_dt <- dt[1:cut]
test_dt  <- dt[(cut+1):n]
```

### 6. Fit and evaluate models

We define a helper function that fits a **random forest model** using the `ranger` package and evaluates its performance on the test set. Model performance is assessed using two metrics:

```{r}
score_model <- function(train_dt, test_dt, drop_cols = character()) {
  x_cols <- setdiff(names(train_dt), c("date","n_trips", drop_cols))
  
  fit <- ranger(
    formula = as.formula(paste("n_trips ~", paste(x_cols, collapse = " + "))),
    data = train_dt,
    num.trees = 500,
    mtry = max(1, floor(sqrt(length(x_cols)))),
    min.node.size = 10,
    num.threads = max(1, parallel::detectCores() - 1)
  )
  
  p <- predict(fit, data = test_dt)$predictions
  rmse <- sqrt(mean((test_dt$n_trips - p)^2))
  r2   <- 1 - sum((test_dt$n_trips - p)^2) / sum((test_dt$n_trips - mean(test_dt$n_trips))^2)
  
  list(rmse = rmse, r2 = r2)
}
```

### 7. Baseline model 

We first fit a baseline random forest model that includes both temperature and precipitation. The RMSE and R² from this full model serve as reference benchmarks for evaluating the impact of removing each weather variable in the LOCO analysis.

```{r}
base <- score_model(train_dt, test_dt, drop_cols = character())

cat("\nFull model (Temp + Precip)\n")
cat("RMSE:", round(base$rmse, 1), "\n")
cat("R^2 :", round(base$r2, 3), "\n")
```

### 8. LOCO: Temperature vs. Precipitation

We apply the leave-one-covariate-out (LOCO) procedure by refitting the model twice:

-    **Remove temperature:** the model is trained using precipitation only.

-   **Remove precipitation:** the model is trained using temperature only

```{r}
loco <- rbindlist(list(
  
  {
    res <- score_model(train_dt, test_dt, drop_cols = "temp_mean_F")
    data.table(
      component   = "Temperature",
      rmse        = res$rmse,
      r2          = res$r2
    )
  },
  
  {
    res <- score_model(train_dt, test_dt, drop_cols = "precip_in")
    data.table(
      component   = "Precipitation",
      rmse        = res$rmse,
      r2          = res$r2
    )
  }
  
), fill = TRUE)

# Compute deltas vs full model
loco[, `:=`(
  delta_rmse = rmse - base$rmse,
  delta_r2   = r2   - base$r2
)]

setorder(loco, -delta_rmse)
loco[, rank := frank(-delta_rmse, ties.method = "first")]
setcolorder(loco, c("rank","component","rmse","r2","delta_rmse","delta_r2"))

print(loco)
```

### 9. Interpreting the results

```{r}
loco |>
  gt() |>
  cols_label(
    rank = "Rank",
    component = "Dropped",
    rmse = "RMSE (LOCO)",
    r2 = "R² (LOCO)",
    delta_rmse = "Δ RMSE vs Full",
    delta_r2 = "Δ R² vs Full"
  ) |>
  fmt_number(columns = c(rmse, delta_rmse), decimals = 0) |>
  fmt_number(columns = c(r2, delta_r2), decimals = 3) |>
  tab_header(title = "LOCO Weather Importance: Temperature vs Precipitation")
```

The LOCO analysis shows that between the two variables, temperature is the stronger predictor of daily Citi Bike ridership compared to precipitation. When temperature is removed from the model, prediction accuracy declines substantially: the typical prediction error increases by roughly 14,000 trips per day, and the model’s R² becomes strongly negative. This indicates that the model without temperature performs much worse than simply predicting the average number of daily trips, highlighting how essential temperature is for capturing day-to-day variation in ridership.

In contrast, removing precipitation also reduces model performance, but to a lesser degree. The increase in prediction error is about 6,300 trips per day, and the drop in R² is smaller than when temperature is removed. This suggests that precipitation provides useful information, particularly for suppressing ridership on rainy days, but it does not explain as much overall variation as temperature.

Some limitations to note are that the effect of precipitation may be understated in this analysis because rainfall is sporadic and short-lived, rather than a consistent condition throughout the day. Aggregating precipitation to the daily level can mask important within-day variation, such as brief rain events that strongly suppress ridership during specific hours but do not persist long enough to substantially affect the daily total.

An hourly analysis would better capture these short-term behavioral responses to rain. However, due to memory and computational constraints associated with processing the full trip-level dataset at an hourly resolution, we default to a daily aggregation. As a result, the LOCO comparison likely favors temperature due to exerting a more persistent, day-long influence, while underrepresenting the true impact of precipitation.
